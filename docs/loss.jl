# notes on the fuzzy set cross entropy loss for UMAP

"""
Given two fuzzy simplicial sets, we can consider the 1-skeleta as
a fuzzy graph (i.e. a set of edges, where each edge has a probability of existing
in the graph). The two sets (of edges) can be compared by computing the
set cross entropy.

For a set A and membership functions Î¼: A â†’ [0, 1], Î½: A â†’ [0, 1], the set cross
entropy is:
"""

function cross_entropy(A::Set, Î¼, Î½)
    loss = 0
    for a âˆˆ A
        loss += Î¼(a) * log(Î¼(a) / Î½(a)) + (1 - Î¼(a)) * log((1 - Î¼(a)) / (1 - Î½(a)))
    end
    return loss
end

"""
The loss function can be generalized to ğ’-skeleta by the weighted sum of the
set cross entropies of the fuzzy sets of ğ‘–-simplices. That is,

C_l(X, Y) = Î£_{i=1}^{l}(Î»áµ¢ * C(Xáµ¢, Yáµ¢)),

where Xáµ¢ denotes the ğ‘–-simplices of X.
"""
function cross_entropy(ğ€::Vector{Set}, Î¼, Î½)
    loss = 0
    for A in ğ€
        loss += cross_entropy(A, Î¼, Î½)
    end
end

"""
During optimization, we can simplify the loss function to only consider terms
that aren't fixed values and minimize that:

C(A, Î¼, Î½) = - Î£_{a âˆˆ A} ( Î¼(a) * log(Î½(a)) + (1 - Î¼(a)) * log(1 - Î½(a)))
"""
function cross_entropy(A::Set, Î¼, Î½)
    loss = 0
    for a âˆˆ A
        loss += Î¼(a) * log(Î½(a)) + (1 - Î¼(a)) * log(1 - Î½(a))
    end
    return -loss
end

"""
Instead of calculating the loss over the entire set (if our set is comprised
of the 1-simplices, then calculating this loss would have time complexity
ğ’ª(nÂ²)), we can sample elements with probability Î¼(a) and update according to
the value Î½(a). This takes care of the Î¼(a) * log(Î½(a)) term. For the
negative samples, elements are sampled uniformly and assumed to have Î¼(a) = 0.
This results in a sampling distribution of

P(xáµ¢) = Î£_{a âˆˆ A | dâ‚€(a) = xáµ¢}(1 - Î¼(a)) / Î£_{b âˆˆ A | dâ‚€(b) â‰  xáµ¢}(1 - Î¼(b)),

which is approximately uniform for sufficiently large datasets.
"""
function sample_distribution(X, A, Î¼) end

"""
To optimize this loss with gradient descent, Î½(v) must be differentiable. A
smooth approximation for the membership strength of a 1-simplex between two
points x, y, can be given by the following, with dissimilarity function `Ïƒ`,
and constants `Î±`, `Î²`:
"""
Ï•(x, y, Ïƒ, Î±, Î²) = (1 + Î±*(Ïƒ(x, y))^Î²)^(-1)

"""
The approximation parameters `Î±`, `Î²` are chosen by non-linear least squares
fitting of the following function Ïˆ:
"""
Ïˆ(x, y, Ïƒ, min_dist) = 1 if Ïƒ(x, y) â‰¤ min_dist else exp(-(Ïƒ(x, y) - min_dist))

"""
Optimizing the embedding is therefore accomplished by the following, where
`fs_set` is the set of ğ’-simplices (1-simplices most likely), `Y_emb` is the
target embeddings of the points that make up the vertices of `fs_set`, Ïƒ is
a differentiable distance measure between points in `Y_emb`, and `Ï•` is the
differentiable approximation to the fuzzy set membership function for the
simplices in the target embedding.
"""
function optimize_embedding(fs_set, Y_emb, Ïƒ, Ï•, n_epochs, n_neg_samples)
    Î· = 1
    âˆ‡logÏ•(x, y) = gradient((_x, _y) -> log(Ï•(_x, _y, Ïƒ)), x, y)
    âˆ‡log1_Ï•(x, y) = gradient((_x, _y) -> log(1 - Ï•(_x, _y, Î±)), x, y)
    for e in 1:n_epochs
        for (a, b, p) in fs_setâ‚ # 1-simplices here
            if rand() â‰¤ p
                âˆ‚a, âˆ‚b = Î· * âˆ‡logÏ•(Y_emb[a], Y_emb[b])
                Y_emb[a] -= âˆ‚a
                # Y_emb[b] -= âˆ‚b
                for _ in 1:n_neg_samples
                    c = sample(Y_emb)
                    âˆ‚a, âˆ‚c = Î· * âˆ‡log1_Ï•(Y_emb[a], Y_emb[c])
                    Y_emb[a] -= âˆ‚a
                    # Y_emb[c] -= âˆ‚c
                end
            end
        end
        Î· = 1 - e/n_epochs
    end
    return Y_emb
end
